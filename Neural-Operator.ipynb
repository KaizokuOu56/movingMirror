{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ad6d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from neuralop.models import FNO\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from scipy.special import legendre, chebyt, jv, hermite, eval_laguerre\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad1022a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_types = [\n",
    "    \"fourier\",          # sum of sinusoids\n",
    "    \"poly\",             # standard polynomial\n",
    "    \"gaussian\",         # single Gaussian\n",
    "    \"gaussian_mixture\", # sum of Gaussians\n",
    "    \"damped_sine\",      # exponentially damped sinusoid\n",
    "    \"exp_decay\",        # exponential decay\n",
    "    \"piecewise\",        # piecewise linear/quadratic\n",
    "    \"trig_combo\",       # combination of sin and cos\n",
    "    \"legendre\",         # Legendre polynomials\n",
    "    \"chebyshev\",        # Chebyshev polynomials (1st kind)\n",
    "    \"bessel\",           # Bessel function of first kind\n",
    "    \"hermite\",          # Hermite polynomials\n",
    "    \"laguerre\",         # Laguerre polynomials\n",
    "    \"windowed_sine\",    # sinusoid multiplied by Gaussian\n",
    "    \"rect_pulse\",       # rectangular pulse\n",
    "    \"sawtooth\",         # sawtooth wave\n",
    "    \"triangle\",         # triangle wave\n",
    "    \"modulated\",        # product of sinusoids (beats)\n",
    "    \"chirp\",            # frequency-increasing sinusoid\n",
    "    \"spikes\",           # sparse impulses\n",
    "    \"wavelet\"           # Mexican hat wavelet\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a4bd56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_function(x, kind=\"random\", max_freq=10):\n",
    "    \"\"\"\n",
    "    Generate a diverse set of functions for Fourier testing.\n",
    "\n",
    "    Parameters:\n",
    "        x        : array of input points\n",
    "        kind     : type of function to generate; if 'random', one is picked randomly\n",
    "        max_freq : maximum frequency for Fourier-type functions\n",
    "\n",
    "    Returns:\n",
    "        f        : array of function values\n",
    "    \"\"\"\n",
    "    \n",
    "    if kind == \"random\":\n",
    "        kind = np.random.choice(function_types)\n",
    "    \n",
    "    # ----------------- Standard types -----------------\n",
    "    if kind == \"fourier\":\n",
    "        coeffs = np.random.randn(max_freq)\n",
    "        f = np.zeros_like(x, dtype=float)\n",
    "        for n, a in enumerate(coeffs, start=1):\n",
    "            f += a * np.sin(np.pi * n * x)\n",
    "        return f\n",
    "\n",
    "    elif kind == \"poly\":\n",
    "        coeffs = np.random.randn(5)\n",
    "        return sum(c * x**i for i, c in enumerate(coeffs))\n",
    "\n",
    "    elif kind == \"gaussian\":\n",
    "        mu, sigma = np.random.uniform(-0.5, 0.5), np.random.uniform(0.05, 0.5)\n",
    "        return np.exp(-((x - mu) ** 2) / (2 * sigma ** 2))\n",
    "\n",
    "    elif kind == \"gaussian_mixture\":\n",
    "        num_gaussians = np.random.randint(2, 4)\n",
    "        f = np.zeros_like(x)\n",
    "        for _ in range(num_gaussians):\n",
    "            mu, sigma, amp = np.random.uniform(-0.5,0.5), np.random.uniform(0.05,0.3), np.random.uniform(0.5,2.0)\n",
    "            f += amp * np.exp(-((x - mu)**2) / (2 * sigma**2))\n",
    "        return f\n",
    "\n",
    "    elif kind == \"damped_sine\":\n",
    "        freq = np.random.uniform(1, max_freq)\n",
    "        decay = np.random.uniform(0.5, 2.0)\n",
    "        phase = np.random.uniform(0, 2*np.pi)\n",
    "        return np.exp(-decay * np.abs(x)) * np.sin(2 * np.pi * freq * x + phase)\n",
    "\n",
    "    elif kind == \"exp_decay\":\n",
    "        lam = np.random.uniform(0.5, 2.0)\n",
    "        return np.exp(-lam * np.abs(x))\n",
    "\n",
    "    elif kind == \"piecewise\":\n",
    "        split = np.random.uniform(x[0], x[-1])\n",
    "        return np.piecewise(x, [x < split, x >= split],\n",
    "                            [lambda t: t**2, lambda t: -t + split])\n",
    "\n",
    "    elif kind == \"trig_combo\":\n",
    "        f = np.zeros_like(x)\n",
    "        num_terms = np.random.randint(2, 5)\n",
    "        for _ in range(num_terms):\n",
    "            amp = np.random.uniform(0.5, 2.0)\n",
    "            freq = np.random.randint(1, max_freq)\n",
    "            phase = np.random.uniform(0, 2*np.pi)\n",
    "            f += amp * (np.sin(2*np.pi*freq*x + phase) + np.cos(2*np.pi*freq*x + phase))\n",
    "        return f\n",
    "\n",
    "    # ----------------- Special polynomials -----------------\n",
    "    elif kind == \"legendre\":\n",
    "        deg = np.random.randint(1, 6)\n",
    "        P = legendre(deg)\n",
    "        return P(x)\n",
    "\n",
    "    elif kind == \"chebyshev\":\n",
    "        deg = np.random.randint(1, 6)\n",
    "        T = chebyt(deg)\n",
    "        return T(x)\n",
    "\n",
    "    elif kind == \"bessel\":\n",
    "        order = np.random.randint(0, 6)\n",
    "        k = np.random.uniform(1, 10)\n",
    "        return jv(order, k * x)\n",
    "\n",
    "    elif kind == \"hermite\":\n",
    "        deg = np.random.randint(1,5)\n",
    "        H = hermite(deg)\n",
    "        return H(x)\n",
    "\n",
    "    elif kind == \"laguerre\":\n",
    "        deg = np.random.randint(1,5)\n",
    "        return eval_laguerre(deg, np.abs(x))  # Laguerre defined on [0,âˆž)\n",
    "\n",
    "    # ----------------- Windowed / localized functions -----------------\n",
    "    elif kind == \"windowed_sine\":\n",
    "        freq = np.random.uniform(1, max_freq)\n",
    "        alpha = np.random.uniform(1,5)\n",
    "        return np.sin(2*np.pi*freq*x) * np.exp(-alpha*x**2)\n",
    "\n",
    "    elif kind == \"rect_pulse\":\n",
    "        start, end = np.random.uniform(-0.5, 0), np.random.uniform(0,0.5)\n",
    "        return np.where((x>=start) & (x<=end), 1.0, 0.0)\n",
    "\n",
    "    elif kind == \"sawtooth\":\n",
    "        return 2*(x - np.floor(x + 0.5))  # normalized sawtooth\n",
    "\n",
    "    elif kind == \"triangle\":\n",
    "        return 2*np.abs(2*(x - np.floor(x + 0.5))) - 1\n",
    "\n",
    "    elif kind == \"modulated\":\n",
    "        f1 = np.sin(5*np.pi*x)\n",
    "        f2 = np.cos(2*np.pi*x)\n",
    "        return f1*f2\n",
    "\n",
    "    elif kind == \"chirp\":\n",
    "        return np.sin(2*np.pi*(x + x**2))\n",
    "\n",
    "    elif kind == \"spikes\":\n",
    "        f = np.zeros_like(x)\n",
    "        num_spikes = np.random.randint(3,8)\n",
    "        indices = np.random.choice(len(x), num_spikes, replace=False)\n",
    "        f[indices] = np.random.uniform(1,3, size=num_spikes)\n",
    "        return f\n",
    "\n",
    "    elif kind == \"wavelet\":\n",
    "        return (1 - x**2) * np.exp(-x**2 / 2)  # Mexican hat\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown function type '{kind}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5241312",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOMAIN = (-np.pi, np.pi)\n",
    "RESOLUTION = 256\n",
    "TRAIN_SAMPLES = 2000\n",
    "TEST_SAMPLES = 200\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abcb86a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fourier_dataset(num_samples=TRAIN_SAMPLES, resolution=RESOLUTION):\n",
    "    \"\"\"Generate dataset of functions and their Fourier transforms\"\"\"\n",
    "    x = torch.linspace(DOMAIN[0], DOMAIN[1], resolution)\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        # Create random function as sum of sinusoids\n",
    "        f = torch.Tensor(make_function(x.numpy(), kind=\"random\", max_freq=10))\n",
    "        \n",
    "        # Compute Fourier transform\n",
    "        ft = torch.fft.fft(f)\n",
    "        # Stack real and imaginary parts\n",
    "        ft_real_imag = torch.stack([ft.real, ft.imag], dim=0)\n",
    "        \n",
    "        inputs.append(f.unsqueeze(0))  # Add channel dimension: (1, resolution)\n",
    "        outputs.append(ft_real_imag)   # (2, resolution) - real and imag parts\n",
    "    \n",
    "    # Stack all samples: (num_samples, channels, resolution)\n",
    "    X = torch.stack(inputs)     # (num_samples, 1, resolution)  \n",
    "    Y = torch.stack(outputs)    # (num_samples, 2, resolution)\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "X_train, Y_train = generate_fourier_dataset(num_samples=TRAIN_SAMPLES, resolution=RESOLUTION)\n",
    "X_val, Y_val = generate_fourier_dataset(num_samples=TEST_SAMPLES, resolution=RESOLUTION)\n",
    "X_test, Y_test = generate_fourier_dataset(num_samples=TEST_SAMPLES, resolution=RESOLUTION)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "val_dataset = TensorDataset(X_val, Y_val)\n",
    "test_dataset = TensorDataset(X_test, Y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0ae9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNO(\n",
      "  (positional_embedding): GridEmbeddingND()\n",
      "  (fno_blocks): FNOBlocks(\n",
      "    (convs): ModuleList(\n",
      "      (0-3): 4 x SpectralConv(\n",
      "        (weight): DenseTensor(shape=torch.Size([64, 64, 17]), rank=None)\n",
      "      )\n",
      "    )\n",
      "    (fno_skips): ModuleList(\n",
      "      (0-3): 4 x Flattened1dConv(\n",
      "        (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (channel_mlp): ModuleList(\n",
      "      (0-3): 4 x ChannelMLP(\n",
      "        (fcs): ModuleList(\n",
      "          (0): Conv1d(64, 32, kernel_size=(1,), stride=(1,))\n",
      "          (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (channel_mlp_skips): ModuleList(\n",
      "      (0-3): 4 x SoftGating()\n",
      "    )\n",
      "  )\n",
      "  (lifting): ChannelMLP(\n",
      "    (fcs): ModuleList(\n",
      "      (0): Conv1d(2, 128, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (projection): ChannelMLP(\n",
      "    (fcs): ModuleList(\n",
      "      (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(128, 2, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = FNO(\n",
    "    n_modes=(32,),           # Number of Fourier modes for 1D\n",
    "    hidden_channels=64,      # Width of the network\n",
    "    in_channels=1,           # Input: single function\n",
    "    out_channels=2,          # Output: real and imaginary parts\n",
    "    n_layers=4,              # Number of FNO layers\n",
    "    factorization=None       # No tensorization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16f54bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FNO(\n",
       "  (positional_embedding): GridEmbeddingND()\n",
       "  (fno_blocks): FNOBlocks(\n",
       "    (convs): ModuleList(\n",
       "      (0-3): 4 x SpectralConv(\n",
       "        (weight): DenseTensor(shape=torch.Size([64, 64, 17]), rank=None)\n",
       "      )\n",
       "    )\n",
       "    (fno_skips): ModuleList(\n",
       "      (0-3): 4 x Flattened1dConv(\n",
       "        (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (channel_mlp): ModuleList(\n",
       "      (0-3): 4 x ChannelMLP(\n",
       "        (fcs): ModuleList(\n",
       "          (0): Conv1d(64, 32, kernel_size=(1,), stride=(1,))\n",
       "          (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (channel_mlp_skips): ModuleList(\n",
       "      (0-3): 4 x SoftGating()\n",
       "    )\n",
       "  )\n",
       "  (lifting): ChannelMLP(\n",
       "    (fcs): ModuleList(\n",
       "      (0): Conv1d(2, 128, kernel_size=(1,), stride=(1,))\n",
       "      (1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (projection): ChannelMLP(\n",
       "    (fcs): ModuleList(\n",
       "      (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "      (1): Conv1d(128, 2, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "criterion = nn.MSELoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ea81635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Train Loss: 15438.202699, Val Loss: 13090.276280\n",
      "Epoch [20/50], Train Loss: 6193.406149, Val Loss: 9914.399152\n",
      "Epoch [30/50], Train Loss: 4665.404650, Val Loss: 8718.177211\n",
      "Epoch [40/50], Train Loss: 4220.761840, Val Loss: 8415.488713\n",
      "Epoch [50/50], Train Loss: 4017.259726, Val Loss: 8359.490060\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Training phase\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            val_loss += criterion(output, target).item()\n",
    "\n",
    "    # Update scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}')\n",
    "\n",
    "metrics = {\"Training Loss\": avg_train_loss, \"Validation Loss\": avg_val_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "245694ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anshul-jawale/Anshul/Code/Moving-Mirror/env/lib/python3.12/site-packages/tltorch/factorized_tensors/factorized_tensors.py:66: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  return self.__class__(self.tensor[indices])\n",
      "/home/anshul-jawale/Anshul/Code/Moving-Mirror/env/lib/python3.12/site-packages/neuralop/layers/spectral_convolution.py:468: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  out_fft[slices_x] = self._contract(x[slices_x], weight, separable=self.separable)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3404.498413\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).item()\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "metrics[\"Test Loss\"] = avg_test_loss\n",
    "print(f\"Test Loss: {avg_test_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef633f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Test Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FNO</th>\n",
       "      <td>4017.259726</td>\n",
       "      <td>8359.49006</td>\n",
       "      <td>3404.498413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Training Loss  Validation Loss    Test Loss\n",
       "FNO    4017.259726       8359.49006  3404.498413"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(metrics, index=[model._name])\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b495a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_function(f):\n",
    "    # Generate test data\n",
    "    x_test = torch.linspace(DOMAIN[0], DOMAIN[1], RESOLUTION)\n",
    "    f_test = f(x_test)\n",
    "\n",
    "    # True Fourier transform\n",
    "    ft_true = torch.fft.fft(f_test)\n",
    "\n",
    "    # Predict using trained model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Prepare input: add batch and channel dimensions\n",
    "        f_input = f_test.unsqueeze(0).unsqueeze(0).to(device)  \n",
    "        ft_pred = model(f_input).cpu().squeeze(0)              \n",
    "\n",
    "    # Plot results\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Original function\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(x_test.numpy(), f_test.numpy())\n",
    "    plt.title('Input Function')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('f(x)')\n",
    "\n",
    "    # Real part comparison\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(ft_true.real.numpy(), label='True Real', linewidth=2)\n",
    "    plt.plot(ft_pred[0].numpy(), '--', label='Predicted Real', linewidth=2)\n",
    "    plt.title('Fourier Transform - Real Part')\n",
    "    plt.legend()\n",
    "\n",
    "    # Imaginary part comparison\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(ft_true.imag.numpy(), label='True Imag', linewidth=2)\n",
    "    plt.plot(ft_pred[1].numpy(), '--', label='Predicted Imag', linewidth=2)\n",
    "    plt.title('Fourier Transform - Imaginary Part')\n",
    "    plt.legend()\n",
    "\n",
    "    # Magnitude comparison\n",
    "    plt.subplot(2, 2, 2)\n",
    "    ft_true_mag = torch.abs(ft_true)\n",
    "    ft_pred_complex = ft_pred[0] + 1j * ft_pred[1]\n",
    "    ft_pred_mag = torch.abs(ft_pred_complex)\n",
    "    plt.plot(ft_true_mag.numpy(), label='True Magnitude', linewidth=2)\n",
    "    plt.plot(ft_pred_mag.numpy(), '--', label='Predicted Magnitude', linewidth=2)\n",
    "    plt.title('Fourier Transform - Magnitude')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print error metrics\n",
    "    mse_real = torch.mean((ft_true.real - ft_pred[0])**2)\n",
    "    mse_imag = torch.mean((ft_true.imag - ft_pred[1])**2)\n",
    "    mse = torch.mean((ft_true_mag - ft_pred_mag)**2)\n",
    "    print(f\"MSE Real Part: {mse_real.item():.6f}\")\n",
    "    print(f\"MSE Imaginary Part: {mse_imag.item():.6f}\")\n",
    "    print(f\"MSE Magnitude: {mse.item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baba47e1",
   "metadata": {},
   "source": [
    "### To be fixed\n",
    "-   Use a more focussed training data\n",
    "-   Change layers/channels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
